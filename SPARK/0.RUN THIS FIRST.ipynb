{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 4234-2518\n",
      "\n",
      " Directory of C:\\Users\\ANTHONY\\Desktop\\important ipynb codes\\SPARK\n",
      "\n",
      "11-05-2021  08:21 AM    <DIR>          .\n",
      "11-05-2021  08:21 AM    <DIR>          ..\n",
      "11-05-2021  08:20 AM    <DIR>          .ipynb_checkpoints\n",
      "11-05-2021  08:19 AM           289,955 1.Context , session and data import.ipynb\n",
      "03-04-2021  07:35 PM            99,155 2. Schemas_Columns_rows_groupby_sort_unique.ipynb\n",
      "03-04-2021  08:37 PM            23,185 3. Built_in_functions.ipynb\n",
      "05-04-2021  09:43 AM            84,261 3.Functions&date&joins.ipynb\n",
      "03-04-2021  09:23 AM             4,046 Download_data.ipynb\n",
      "03-04-2021  07:33 PM             2,294 FIRST_SAMPLE.ipynb\n",
      "05-05-2021  09:05 PM    <DIR>          New Folder\n",
      "19-08-2019  06:56 AM             5,699 police_station.csv\n",
      "05-04-2021  10:03 AM            22,987 RDD.ipynb\n",
      "02-04-2021  04:48 PM       171,057,223 reported-crimes.csv\n",
      "02-04-2021  04:48 PM       171,057,223 rows.csv@accessType=DOWNLOAD\n",
      "11-05-2021  08:21 AM             3,319 RUN THIS FIRST.ipynb\n",
      "02-06-2018  02:19 AM    <DIR>          spark-2.3.1-bin-hadoop2.7\n",
      "11-05-2021  08:22 AM        29,986,650 spark-2.3.1-bin-hadoop2.7.tgz\n",
      "03-04-2021  12:53 PM             6,910 Working_with_columns.ipynb\n",
      "03-04-2021  09:00 PM             6,829 Working_with_dates.ipynb\n",
      "03-04-2021  01:31 PM             6,581 Working_with_rows.ipynb\n",
      "              15 File(s)    372,656,317 bytes\n",
      "               5 Dir(s)  171,443,949,568 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-MI2531VA:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-MI2531VA:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25e6a4db190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
