{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " working with audio and spoken language files is different to other kinds of data. First of all, unlike text or tabular data, you can't immediately see what you're working with. So many audio files often require a conversion step before you can begin working with them. And because of the frequency measure, even a few seconds of audio can contain large amounts of data. Add in background noise, other sounds, more speakers and the number of pieces of information grows even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONVERT WAV FILES TO BYTE FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xfd\\xff\\xfb\\xff\\xf8\\xff\\xf8\\xff\\xf7\\xff'\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import numpy as np \n",
    "\n",
    "address=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/good_morning.wav\"\n",
    "\n",
    "# Create audio file wave object\n",
    "good_morning = wave.open(address, 'r')\n",
    "\n",
    "# Read all frames from wave object \n",
    "signal_gm = good_morning.readframes(-1)\n",
    "\n",
    "# View first 10\n",
    "print(signal_gm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting sound wave bytes to integers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3  -5  -8  -8  -9 -13  -8 -10  -9 -11]\n"
     ]
    }
   ],
   "source": [
    "# Convert good morning audio bytes to integers\n",
    "soundwave_gm = np.frombuffer(signal_gm, dtype='int16')\n",
    "\n",
    "# View the first 10 sound wave values in integer form\n",
    "print(soundwave_gm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the time stamps\n",
    "We know the frequency of our sound wave is 48 kHz, but what if we didn't? We could find it by dividing the length of our sound wave array by the duration of our sound wave. However, Python's wave module has a better way. Calling getframerate() on a wave object returns the frame rate of that wave object.\n",
    "\n",
    "#in this below case\n",
    "\n",
    "Start will be 0 for the beginning of the audio file. \n",
    "\n",
    "Stop will be the length of our sound wave array over the framerate, or in other words, the duration.\n",
    "\n",
    "And num will be the length of our sound wave array, since each item in the array is a sound wave value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "5.208\n",
      "[0.00000000e+00 2.08334167e-05 4.16668333e-05 6.25002500e-05\n",
      " 8.33336667e-05 1.04167083e-04 1.25000500e-04 1.45833917e-04\n",
      " 1.66667333e-04 1.87500750e-04]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the sound wave frame rate\n",
    "framerate_gm = good_morning.getframerate()\n",
    "print(framerate_gm)\n",
    "\n",
    "duration=len(soundwave_gm)/framerate_gm\n",
    "print(duration)\n",
    "\n",
    "# Find the sound wave timestamps\n",
    "time_gm = np.linspace(start=0,\n",
    "                      stop=len(soundwave_gm)/framerate_gm,\n",
    "                      num=len(soundwave_gm))\n",
    "\n",
    "# Print the first 10 timestamps\n",
    "print(time_gm[:10])    #Each of these values is the time in seconds where each sound wave byte occurred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOTHER METHOD TO FIND DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.604\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "\n",
    "with contextlib.closing(wave.open(address,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / float(rate)\n",
    "    print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xb1\\xff\\xca\\xff\\xb0\\xff\\xcf\\xff\\xab\\xff'\n",
      "[-79 -54 -80 -49 -85 -45 -87 -51 -87 -58]\n"
     ]
    }
   ],
   "source": [
    "address1=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/good_afternoon.wav\"\n",
    "\n",
    "# Create audio file wave object\n",
    "good_afternoon = wave.open(address1, 'r')\n",
    "\n",
    "# Read all frames from wave object \n",
    "signal_ga = good_afternoon.readframes(-1)\n",
    "\n",
    "# View first 10 in byte form\n",
    "print(signal_ga[:10])\n",
    "\n",
    "# Convert good morning audio bytes to integers\n",
    "soundwave_ga = np.frombuffer(signal_ga, dtype='int16')\n",
    "\n",
    "# View the first 10 sound wave values in integer form\n",
    "print(soundwave_ga[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "2.604\n",
      "[0.00000000e+00 2.08333960e-05 4.16667921e-05 6.25001881e-05\n",
      " 8.33335841e-05 1.04166980e-04 1.25000376e-04 1.45833772e-04\n",
      " 1.66667168e-04 1.87500564e-04]\n"
     ]
    }
   ],
   "source": [
    "# Get the sound wave frame rate\n",
    "framerate_ga = good_afternoon.getframerate()\n",
    "print(framerate_ga)\n",
    "\n",
    "duration1=len(soundwave_ga)/framerate_ga\n",
    "print(duration)\n",
    "\n",
    "# Find the sound wave timestamps\n",
    "time_ga = np.linspace(start=0,\n",
    "                      stop=len(soundwave_ga)/framerate_ga,\n",
    "                      num=len(soundwave_ga))\n",
    "\n",
    "# Print the first 10 timestamps\n",
    "print(time_ga[:10])    #Each of these values is the time in seconds where each sound wave byte occurred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the title and axis titles\n",
    "plt.title('Good Afternoon vs. Good Morning')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.xlabel('Time (seconds)')\n",
    "\n",
    "# Add the Good Afternoon data to the plot                                x=time stamp   &    y=integer form\n",
    "plt.plot(time_ga, soundwave_ga, label='Good Afternoon')\n",
    "\n",
    "# Add the Good Morning data to the plot\n",
    "plt.plot(time_gm, soundwave_gm, label='Good Morning',\n",
    "   # Set the alpha variable to 0.5 so that it becomes transaprent\n",
    "   alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechRecognition library?\n",
    "Automatic speech recognition is a tough challenge. And there's no shortage of companies and research institutions working on libraries to help solve it. There's the \n",
    "\n",
    "CMU Sphinx library by Carnegie Mellon University,\n",
    "\n",
    "Kaldi,\n",
    "\n",
    "SpeechRecognition\n",
    "\n",
    "Wav2letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the speech_recognition library\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Create an instance of the Recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Set the energy threshold----The energy_threshold is a number between 0 and 4000 for how much the Recognizer class should listen to an audio file.\n",
    "recognizer.energy_threshold = 300   #here anything below 300 is silence and above is audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've created an instance of the Recognizer class we'll use the recognize_google() method on it to access the Google web speech API and turn spoken language into text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I want to get some help setting up my time please\n"
     ]
    }
   ],
   "source": [
    "\n",
    "call_audio=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\"\n",
    "\n",
    "#now we need some preprosseing to convert it into audio data file\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "clean_support_call = sr.AudioFile(call_audio)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with clean_support_call as source:\n",
    "    clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe AudioData to text...................We are using googles api that is free and dont need an api key\n",
    "text = recognizer.recognize_google(clean_support_call_audio,language=\"en-US\")\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may DO NOT want the entire audio file you're working with. The duration and offset parameters of the record() method can help with this.\n",
    "\n",
    "After exploring your dataset, you find there's one file, imported as nothing_at_end which has 30-seconds of silence at the end and a support call file, imported as out_of_warranty has 3-seconds of static at the front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Odia call has 30 seconds of nothing at the end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thirty_audio=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/30_seconds_of_nothing_16k.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "nothing_at_end = sr.AudioFile(thirty_audio)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with nothing_at_end as source:\n",
    "    nothing_at_end_audio = recognizer.record(source,       #only give 10 seconds. with offset =10 it gives first 10 seconds\n",
    "                                             duration=10,\n",
    "                                             offset=None)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(nothing_at_end_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I like to get some help with my device please I think it's I want I want to do back to you\n"
     ]
    }
   ],
   "source": [
    "ten_audio=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/static_out_of_warranty.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "nothing_at_end = sr.AudioFile(ten_audio)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with nothing_at_end as source:\n",
    "    nothing_at_end_audio = recognizer.record(source,\n",
    "                                             duration=10,   \n",
    "                                             offset=3)               #this does not take into consideration the first 3 sec\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text1 = recognizer.recognize_google(nothing_at_end_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different kinds of audio\n",
    "\n",
    "##### JAPANESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': 'mass', 'confidence': 0.04715142}, {'transcript': 'ok'}, {'transcript': 'Mars'}, {'transcript': 'mahayog'}], 'final': True}\n",
      "おはようございます\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "jap=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/japanense.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "japanese = sr.AudioFile(jap)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with japanese as source:\n",
    "    japanese_audio = recognizer.record(source)  \n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(japanese_audio, language=\"en-US\",show_all=True)\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text1 = recognizer.recognize_google(japanese_audio, language=\"ja\")\n",
    "\n",
    "# Print the text\n",
    "print(text)\n",
    "\n",
    "# Print the text\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NON SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "leo=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/leopard.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "leopard = sr.AudioFile(leo)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with leopard as source:\n",
    "    leopard_audio = recognizer.record(source)  \n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(leopard_audio, show_all=True)   #wont recogonize .also it wont show error cause of show_all\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non audible human form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "baby=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/baby.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "baby_talk = sr.AudioFile(baby)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with baby_talk as source:\n",
    "    baby_talk_audio = recognizer.record(source)  \n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(leopard_audio, show_all=True)   #wont recogonize .also it wont show error cause of show_all\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple_speakers\n",
    "\n",
    "The problem is that multiple users voice wont be recongonised as different,they will be processed together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limitations of the speech recognition library different speakers am voices was one property tax\n"
     ]
    }
   ],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "speakers=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/multiple_speakers.wav\"\n",
    "\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "multiple_speakers = sr.AudioFile(speakers)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with multiple_speakers as source:\n",
    "    multiple_speakers_audio = recognizer.record(source)  \n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(multiple_speakers_audio, language=\"en-US\")   #wont recogonize .also it wont show error cause of show_all\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciphering between multiple speakers in one audio file is called speaker diarization. However, you've seen the free function we've been using, recognize_google() doesn't have the ability to transcribe different speakers.\n",
    "\n",
    "One way around this, without using one of the paid speech to text services, is to ensure your audio files are single speaker.\n",
    "\n",
    "This means if you were working with phone call data, you would make sure the caller and receiver are recorded separately. Then you could transcribe each file individually.\n",
    "\n",
    "In this exercise, we'll transcribe each of the speakers in our multiple speakers audio file individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'speaker_0.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-409974909d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Transcribe each speaker individually\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeakers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mspeaker_audio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Text from speaker {i}:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# attempt to read the file as WAV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'speaker_0.wav'"
     ]
    }
   ],
   "source": [
    "##################   DONT RUN THIS  #################\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Multiple speakers on different files\n",
    "speakers = [sr.AudioFile(\"speaker_0.wav\"), \n",
    "            sr.AudioFile(\"speaker_1.wav\"), \n",
    "            sr.AudioFile(\"speaker_2.wav\")]\n",
    "\n",
    "# Transcribe each speaker individually\n",
    "for i, speaker in enumerate(speakers):\n",
    "    with speaker as source:\n",
    "        speaker_audio = recognizer.record(source)\n",
    "    print(f\"Text from speaker {i}:\")\n",
    "    print(recognizer.recognize_google(speaker_audio,\n",
    "         \t\t\t\t\t\t\t  language=\"en-US\"))\n",
    "\n",
    "    \n",
    "'''\n",
    "<script.py> output:\n",
    "    Text from speaker 0:\n",
    "    one of the limitations of the speech recognition library\n",
    "    \n",
    "    Text from speaker 1:\n",
    "    is that it doesn't recognise different speakers and voices\n",
    "    \n",
    "    Text from speaker 2:\n",
    "    it will just return it all as one block of text\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOISY SUPPORT CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "call_audio=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/noisy_support_call.wav\"\n",
    "\n",
    "#now we need some preprosseing to convert it into audio data file\n",
    "#there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition.\n",
    "noisy_support_call = sr.AudioFile(call_audio)\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with noisy_support_call as source:\n",
    "    noisy_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe AudioData to text...................We are using googles api that is free and dont need an api key\n",
    "text = recognizer.recognize_google(clean_support_call_audio,language=\"en-US\",show_all=True)\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYDUB\n",
    "\n",
    "PyDub is a Python library made by James Robert which provides a gold mine of tools for manipulating audio files. Becoming familiar with PyDub will give you a programmatic way to ensure your audio files are consistent and in an ideal format for transcription locally or through an API.\n",
    "\n",
    "If you're working with only wav files, PyDub works out of the box. However, for file formats like mp3, you'll need ffmpeg, an open source audio library, which can be installed via ffmpeg dot org.\n",
    "\n",
    "PyDub's AudioSegment class makes it easy to import and manipulate audio files with Python.\n",
    "\n",
    "PyDub works with .wav files without any extra dependencies but for other file types like .mp3, you'll need to install ffmpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\", \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Check the type\n",
    "print(type(wav_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment and play\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\", \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Play the audio file\n",
    "play(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Audio parameters with PyDub\n",
    "Every audio file you work with will have a number of characteristics associated with them, such as, channels, frame rate (or sample rate), sample width and more.\n",
    "\n",
    "Knowing these parameters is useful to ensure your audio files are compatible with various API requirements for speech transcription.\n",
    "\n",
    "For example, many APIs recommend a minimum frame rate (wav_file.frame_rate) of 16,000 Hz.\n",
    "\n",
    "When you create an instance of AudioSegment, PyDub automatically infers these parameters from your audio files and saves them as attributes.\n",
    "\n",
    "In this exercise, we'll explore these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wav_file.frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of channels\n",
    "print(wav_file.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max amplitude\n",
    "print(wav_file.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length in milliseconds=== DURATION\n",
    "print(len(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adjusting audio parameters\n",
    "During your exploratory data analysis, you may find some of the parameters of your audio files differ or are incompatible with speech recognition APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new wav file with adjusted frame rate\n",
    "wav_file_16k = wav_file.set_frame_rate(16000)\n",
    "\n",
    "# Check the frame rate of the new wav file\n",
    "print(wav_file_16k.frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of channels to 1\n",
    "wav_file_1_ch = wav_file.set_channels(1)\n",
    "\n",
    "# Check the number of channels\n",
    "print(wav_file_1_ch.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample_width\n",
    "print(f\"Old sample width: {wav_file.sample_width}\")\n",
    "\n",
    "# Set sample_width to 1\n",
    "wav_file_sw_1 = wav_file.set_sample_width(1)\n",
    "\n",
    "# Check new sample_width\n",
    "print(f\"New sample width: {wav_file_sw_1.sample_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\", \n",
    "                                  format=\"wav\")\n",
    "\n",
    "play(wav_file)\n",
    "\n",
    "# Lower the volume by 60 dB\n",
    "quiet_volume_adjusted = wav_file - 60\n",
    "\n",
    "\n",
    "# Play the audio file\n",
    "play(quiet_volume_adjusted)\n",
    "\n",
    "# Increase the volume by 15 dB\n",
    "louder_volume_adjusted = wav_file + 100\n",
    "\n",
    "play(louder_volume_adjusted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, PyDub's effects module has a function called normalize() which finds the maximum volume of an AudioSegment, then adjusts the rest of the AudioSegment to be in proportion. This means the quiet parts will get a volume boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydub.effects import normalize\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\", \n",
    "                                  format=\"wav\")\n",
    "louder_volume_adjusted = AudioSegment.from_file(file=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/unnormalized.wav\", format=\"wav\")\n",
    "# Normalize target audio file\n",
    "normalized_loud_then_quiet = normalize(louder_volume_adjusted)\n",
    "play(normalized_loud_then_quiet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chopping and changing audio files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import part 1 and part 2 audio files\n",
    "part_1 = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/clean_support_call.wav\", \n",
    "                                  format=\"wav\")\n",
    "part_2 = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/baby.wav\",format=\"wav\")\n",
    "\n",
    "# Remove the first 3 seconds of part 1\n",
    "part_1_removed = part_1[3000:]\n",
    "\n",
    "# Add the remainder of part 1 and part 2 together\n",
    "part_3 = part_1_removed + part_2\n",
    "\n",
    "play(part_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting stereo audio to mono with PyDub\n",
    "If you're trying to transcribe phone calls, there's a chance they've been recorded in stereo format, with one speaker on each channel.\n",
    "\n",
    "As you've seen, it's hard to transcribe an audio file with more than one speaker. One solution is to split the audio file with multiple speakers into single files with individual speakers.\n",
    "\n",
    "PyDub's split_to_mono() function can help with this. When called on an AudioSegment recorded in stereo, it returns a list of two separate AudioSegment's in mono format, one for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import AudioSegment\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Import stereo audio file and check channels\n",
    "stereo_phone_call = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/stereo_call.wav\")\n",
    "print(f\"Stereo number channels: {stereo_phone_call.channels}\")\n",
    "\n",
    "# Split stereo phone call and check channels\n",
    "channels = stereo_phone_call.split_to_mono()\n",
    "print(f\"Split number channels: {channels[0].channels}, {channels[1].channels}\")\n",
    "\n",
    "# Save new channels separately\n",
    "phone_call_channel_1 = channels[0]\n",
    "phone_call_channel_2 = channels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting and reformatting audio files\n",
    "If you've made some changes to your audio files, or if they've got the wrong file extension, you can use PyDub to export and save them as new audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-fe6446aa162a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Import the .mp3 file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmp3_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/mp3_file.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Export the .mp3 file as wav\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import the .mp3 file\n",
    "mp3_file = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/mp3_file.mp3\")\n",
    "\n",
    "# Export the .mp3 file as wav\n",
    "mp3_file.export(out_f=\"mp3_file.wav\",\n",
    "                format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a97114e2b3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/mp3_file.mp3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mp3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "sound = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/mp3_file.mp3\",format='mp3')\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating multiple audio files with PyDub\n",
    "\n",
    "For this exercise, we've setup a folder which has .mp3, .m4a and .aac versions of the good-afternoon audio file.\n",
    "\n",
    "We'll use PyDub to open each of the files and export them as .wav format so they're compatible with speech recognition APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the files in the folder\n",
    "for audio_file in folder:\n",
    "    \n",
    "\t# Create the new .wav filename\n",
    "    wav_filename = os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
    "        \n",
    "    # Read audio_file and export it in wav format\n",
    "    AudioSegment.from_file(audio_file).export(out_f=wav_filename, \n",
    "                                              format=\"wav\")\n",
    "        \n",
    "    print(f\"Creating {wav_filename}...\")\n",
    "    \n",
    "'''<script.py> output:\n",
    "    Creating good_afternoon_mp3.wav...\n",
    "    Creating good_afternoon_m4a.wav...\n",
    "    Creating good_afternoon_aac.wav...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An audio processing workflow\n",
    "You've seen how to import and manipulate a single audio file using PyDub. But what if you had a folder with multiple audio files you needed to convert?\n",
    "\n",
    "In this exercise we'll use PyDub to format a folder of files to be ready to use with speech_recognition.\n",
    "\n",
    "You've found your customer call files all have 3-seconds of static at the start and are quieter than they could be.\n",
    "\n",
    "To fix this, we'll use PyDub to cut the static, increase the sound level and convert them to the .wav extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_static = AudioSegment.from_file(\"account_help.mp3\")\n",
    "\n",
    "\n",
    "for audio_file in folder:\n",
    "    file_with_static = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    # Cut the 3-seconds of static off\n",
    "    file_without_static = file_with_static[3000:]\n",
    "\n",
    "    # Increase the volume by 10dB\n",
    "    louder_file_without_static = file_without_static + 10\n",
    "    \n",
    "    # Create the .wav filename for export\n",
    "    wav_filename = os.path.splitext(os.path.basename(audio_file))[0] + \".wav\"\n",
    "    \n",
    "    # Export the louder file without static as .wav\n",
    "    louder_file_without_static.export(wav_filename, format=\"wav\")\n",
    "    print(f\"Creating {wav_filename}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing text transcribed from spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-22781e5afbf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayback\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/acme_studio_mp3.mp3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m# Test the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "  \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "  # Import audio file\n",
    "  audio = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Create new filename\n",
    "  new_filename = filename.split(\".\")[0] + \".wav\"\n",
    "  \n",
    "  # Export file as .wav\n",
    "  audio.export(new_filename, format=\"wav\")\n",
    "  print(f\"Converting {filename} to {new_filename}...\")\n",
    " \n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "sound = AudioSegment.from_file(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/acme_studio_mp3.mp3\")\n",
    "# Test the function\n",
    "x=convert_to_wav(sound)\n",
    "play(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'call_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-053bcf815d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Try the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcall_1_audio_segment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshow_pydub_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"call_1.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-053bcf815d2b>\u001b[0m in \u001b[0;36mshow_pydub_stats\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;34m\"\"\"Returns different audio attributes related to an audio file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;31m# Create AudioSegment instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0maudio_segment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Print audio attributes and return AudioSegment instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mclose_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'call_1.wav'"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "  \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "  # Create AudioSegment instance\n",
    "  audio_segment = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Print audio attributes and return AudioSegment instance\n",
    "  print(f\"Channels: {audio_segment.channels}\")\n",
    "  print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "  print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "  print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "  print(f\"Length (ms): {len(audio_segment)}\")\n",
    "  return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats(\"call_1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing audio with one line\n",
    "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
    "\n",
    "In this exercise, you'll build transcribe_audio() which takes a filename as input, imports the filename using speech_recognition's AudioFile class and then transcribes it using recognize_google()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'call_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9c343c840721>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Test the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscribe_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"call_1.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-9c343c840721>\u001b[0m in \u001b[0;36mtranscribe_audio\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Import the audio file and convert to audio data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0maudio_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0maudio_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# attempt to read the file as WAV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'call_1.wav'"
     ]
    }
   ],
   "source": [
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(\"call_1.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing sentiment of a phone call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you this is done your from AC mysterious how can I get help you can you sing what's your name in what's wrong with the device is Josh and it was seems to not donate blood save my my my father ok not me Josh what's your number your device constructed on which river bridge 1765\n",
      "{'neg': 0.09, 'neu': 0.813, 'pos': 0.097, 'compound': -0.1351}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio(\"C:/Users/ANTHONY/Desktop/CSV&XLSX/audio_files/stereo_call.wav\")\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying transcribed speech with Sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing audio files for text classification\n",
    "Acme are very impressed with your work so far. So they've sent over two more folders of audio files.\n",
    "\n",
    "One folder is called pre_purchase and contains audio snippets from customers who are pre-purchase, like pre_purchase_audio_25.mp3.\n",
    "\n",
    "And the other is called post_purchase and contains audio snippets from customers who have made a purchase (post-purchase), like post_purchase_audio_27.mp3.\n",
    "\n",
    "Upon inspecting the files you find there's about 50 in each and they're in the .mp3 format.\n",
    "\n",
    "Acme want to know if you can build a classifier to classify future calls. You tell them you sure can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_purchase_audio_25\n",
    "# Convert post purchase\n",
    "for file in post_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)\n",
    "\n",
    "# Convert pre purchase\n",
    "for file in pre_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing phone call excerpts\n",
    "In this exercise, we'll transcribe the audio files we converted to .wav format to text using transcribe_audio().\n",
    "\n",
    "Since there's lots of them and there could be more, we'll build a function create_test_list() which takes a list of filenames of audio files as input and goes through each file transcribing the text.\n",
    "\n",
    "create_test_list() uses our transcribe_audio() function we created earlier and returns a list of strings containing the transcribed text from each audio file.\n",
    "\n",
    "pre_purchase_wav_files and post_purchase_wav_files are lists of audio snippet filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_list(folder):\n",
    "  # Create empty list\n",
    "  text_list = []\n",
    "  \n",
    "  # Go through each file\n",
    "  for file in folder:\n",
    "    # Make sure the file is .wav\n",
    "    if file.endswith(\".wav\"):\n",
    "      print(f\"Transcribing file: {file}...\")\n",
    "      \n",
    "      # Transcribe audio and append text to list\n",
    "      text_list.append(transcribe_audio(file))\n",
    "  return text_list\n",
    "\n",
    "create_text_list(folder)\n",
    "\n",
    "# Transcribe post and pre purchase text\n",
    "post_purchase_text = create_text_list(post_purchase_wav_files)\n",
    "pre_purchase_text = create_text_list(pre_purchase_wav_files)\n",
    "\n",
    "# Inspect the first transcription of post purchase\n",
    "print(post_purchase_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to build a text classifier. But right now, all of our transcribed text data is in two lists, pre_purchase_text and post_purchase_text.\n",
    "\n",
    "To organize it better for building a text classifier as well as for future use, we'll put it together into a pandas DataFrame.\n",
    "\n",
    "To start we'll import pandas as pd then we'll create a post purchase dataframe, post_purchase_df using pd.DataFrame().\n",
    "\n",
    "We'll pass pd.DataFrame() a dictionary containing a \"label\" key with a value of \"post_purchase\" and a \"text\" key with a value of our post_purchase_text list.\n",
    "\n",
    "We'll do the same for pre_purchase_df except with pre_purchase_text.\n",
    "\n",
    "To have all the data in one place, we'll use pd.concat() and pass it the pre and post purchase DataFrames.\n",
    "\n",
    "Instructions\n",
    "0 XP\n",
    "Create post_purchase_df using the post_purchase_text list.\n",
    "Create pre_purchase_df using the pre_purchase_text list.\n",
    "Combine the two DataFrames using pd.concat().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make dataframes with the text\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
    "                                 \"text\": post_purchase_text})\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
    "                                \"text\": pre_purchase_text})\n",
    "\n",
    "# Combine DataFrames\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spoken language text classifier\n",
    "Now you've transcribed some customer call audio data, we'll build a model to classify whether the text from the customer call is pre_purchase or post_purchase.\n",
    "\n",
    "We've got 45 examples of pre_purchase calls and 57 examples of post_purchase calls.\n",
    "\n",
    "The data the model will train on is stored in train_df and the data the model will predict on is stored in test_df.\n",
    "\n",
    "Try printing the .head() of each of these to the console.\n",
    "\n",
    "We'll build an sklearn pipeline using CountVectorizer() and TfidfTransformer() to convert our text samples to numbers and then use a MultinomialNB() classifier to learn what category each sample belongs to.\n",
    "\n",
    "This model will work well on our small example here but for larger amounts of text, you may want to consider something more sophisticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Evaluate the MultinomialNB model\n",
    "predicted = text_classifier.predict(test_df.text)\n",
    "accuracy = 100 * np.mean(predicted == test_df.label)\n",
    "print(f'The model is {accuracy}% accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[35, 50, 50, 50, 54, 60, 77, 248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import stats from scipy library\n",
    "from scipy import stats\n",
    "\n",
    "  \n",
    "# Interquartile range (IQR)\n",
    "IQR = stats.iqr(a, interpolation = 'midpoint')\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1*7+2*9+3*11          1*8+2*10+3*12\n",
    "\n",
    "4*7+5*9+6*11          4*8+5*10+6*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*7+5*9+6*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*8+5*10+6*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
