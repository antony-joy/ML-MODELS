{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate baby names from scratch, you need to have a system that generates short texts quickly. These texts should have a unique style and could actually serve as names for newborn babies. In this exercise, you'll start pre-processing a dataset of people's names so that it can be used to train such a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257995</th>\n",
       "      <td>Carleigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257996</th>\n",
       "      <td>Iyana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257997</th>\n",
       "      <td>Kenley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257998</th>\n",
       "      <td>Sloane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257999</th>\n",
       "      <td>Elianna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           input\n",
       "0           John\n",
       "1        William\n",
       "2          James\n",
       "3        Charles\n",
       "4         George\n",
       "...          ...\n",
       "257995  Carleigh\n",
       "257996     Iyana\n",
       "257997    Kenley\n",
       "257998    Sloane\n",
       "257999   Elianna\n",
       "\n",
       "[258000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "add=\"C:/Users/ANTHONY/Desktop/CSV&XLSX/names.txt\"\n",
    "names_df=pd.read_csv(add,names=[\"input\"])\n",
    "# Print the head of df\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll append the start token at the start of each name and update this column in-place. You'll also create another column which will have the end token appended to each name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tJohn</td>\n",
       "      <td>John\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\tWilliam</td>\n",
       "      <td>William\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tJames</td>\n",
       "      <td>James\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tCharles</td>\n",
       "      <td>Charles\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tGeorge</td>\n",
       "      <td>George\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257995</th>\n",
       "      <td>\\tCarleigh</td>\n",
       "      <td>Carleigh\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257996</th>\n",
       "      <td>\\tIyana</td>\n",
       "      <td>Iyana\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257997</th>\n",
       "      <td>\\tKenley</td>\n",
       "      <td>Kenley\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257998</th>\n",
       "      <td>\\tSloane</td>\n",
       "      <td>Sloane\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257999</th>\n",
       "      <td>\\tElianna</td>\n",
       "      <td>Elianna\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             input      target\n",
       "0           \\tJohn      John\\n\n",
       "1        \\tWilliam   William\\n\n",
       "2          \\tJames     James\\n\n",
       "3        \\tCharles   Charles\\n\n",
       "4         \\tGeorge    George\\n\n",
       "...            ...         ...\n",
       "257995  \\tCarleigh  Carleigh\\n\n",
       "257996     \\tIyana     Iyana\\n\n",
       "257997    \\tKenley    Kenley\\n\n",
       "257998    \\tSloane    Sloane\\n\n",
       "257999   \\tElianna   Elianna\\n\n",
       "\n",
       "[258000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert a tab in front of all the names\n",
    "names_df['input'] = names_df['input'].apply(lambda x : '\\t' + x)\n",
    "\n",
    "# Append a newline at the end of every name\n",
    "# We already appended a tab in front, so the target word should start at index 1\n",
    "names_df['target'] = names_df['input'].apply(lambda x : x[1:len(x)] + '\\n')\n",
    "\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a DataFrame with two columns containing the names with the start and end tokens appended. The next step is to encode these as numeric values because machine learning models only accept numeric inputs.\n",
    "\n",
    "In this exercise, you'll create two dictionaries, char_to_idx and idx_to_char, that will contain mappings of characters to integers, e.g., {'\\t': 0, '\\n': 1, 'a': 2, 'b': 3, ...} and the reverse mappings of integers to characters, e.g, {0: '\\t', 1: '\\n', 2: 'a', 3: 'b', ...}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabulary of Names dataset\n",
    "def get_vocabulary(names):  \n",
    "    # Define vocabulary to be set\n",
    "    all_chars=set()\n",
    "    \n",
    "    # Add the start and end token to the vocabulary\n",
    "    all_chars.add('\\t')\n",
    "    all_chars.add('\\n')  \n",
    "    \n",
    "    # Iterate for each name\n",
    "    for name in names:\n",
    "\n",
    "        # Iterate for each character of the name\n",
    "        for c in name:\n",
    "\n",
    "            if c not in all_chars:\n",
    "            # If the character is not in vocabulary, add it\n",
    "                all_chars.add(c)\n",
    "\n",
    "    # Return the vocabulary\n",
    "    return all_chars\n",
    "vocabulary = get_vocabulary(names_df['input'])\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, 'A': 2, 'B': 3, 'C': 4, 'D': 5, 'E': 6, 'F': 7, 'G': 8, 'H': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'N': 15, 'O': 16, 'P': 17, 'Q': 18, 'R': 19, 'S': 20, 'T': 21, 'U': 22, 'V': 23, 'W': 24, 'X': 25, 'Y': 26, 'Z': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53} \n",
      "\n",
      "{0: '\\t', 1: '\\n', 2: 'A', 3: 'B', 4: 'C', 5: 'D', 6: 'E', 7: 'F', 8: 'G', 9: 'H', 10: 'I', 11: 'J', 12: 'K', 13: 'L', 14: 'M', 15: 'N', 16: 'O', 17: 'P', 18: 'Q', 19: 'R', 20: 'S', 21: 'T', 22: 'U', 23: 'V', 24: 'W', 25: 'X', 26: 'Y', 27: 'Z', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary\n",
    "\n",
    "# Sort the vocabulary\n",
    "vocabulary_sorted = sorted(vocabulary)\n",
    "\n",
    "# Create the mapping of the vocabulary chars to integers\n",
    "char_to_idx = { char : idx for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Create the mapping of the integers to vocabulary chars\n",
    "idx_to_char = { idx : char for idx, char in enumerate(vocabulary_sorted) }\n",
    "\n",
    "# Print the dictionaries\n",
    "print(char_to_idx,\"\\n\")\n",
    "print(idx_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input and target tensors\n",
    "In this exercise, you'll create two tensors to encode the input and the target sequences. The input is a list containing all the names in the dataset. So, the first dimension of the input tensor will be the number of names in the dataset. Each name can be thought of as a string having length equal to the length of the longest name and each character in each name is a one-hot encoded vector of size vocabulary. So, the second and third dimensions of the input tensor will be the length of the longest name and the size of the vocabulary. Similar is the case for the target tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(names):\n",
    "    \"\"\"\n",
    "    Function to return length of the longest name.\n",
    "    Input: list of names\n",
    "    Output: length of the longest name\n",
    "    \"\"\"\n",
    "\n",
    "    # create a list to contain all the name lengths\n",
    "    length_list=[]\n",
    "\n",
    "    # Iterate over all names and save the name length in the list.]\n",
    "    for l in names:\n",
    "        length_list.append(len(l))\n",
    "\n",
    "    # Find the maximum length\n",
    "    max_len = np.max(length_list)\n",
    "\n",
    "    # return maximum length\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Find the length of longest name\n",
    "max_len = get_max_len(names_df['input'])\n",
    "\n",
    "# Initialize the input vector\n",
    "input_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')\n",
    "\n",
    "# Initialize the target vector\n",
    "target_data = np.zeros((len(names_df['input']), max_len+1, len(vocabulary)), dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize input and target vectors with values\n",
    "In the last exercise, you created the input and target tensors of appropriate shape containing all zeros. Now, you'll fill these with actual values. The input and target tensors contain all the names in the dataset. Each name can be thought of as a string having length equal to the length of the longest name and each character in each name is a one-hot encoded vector of size vocabulary.\n",
    "\n",
    "The tensors can be filled-in as follows: input_data[n_idx, p_idx, char_to_idx[char]] will be set to 1 whenever the index of the name in the dataset is n_idx and it contains the character char in position p_idx.\n",
    "\n",
    "The dataset and the character to integer mapping are available in names_df and char_to_idx. The zero tensors from the last exercise are available in input_data and target_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['input']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    input_data[n_idx, c_idx, char_to_idx[char]] = 1\n",
    "\n",
    "# Iterate for each name in the dataset\n",
    "for n_idx, name in enumerate(names_df['target']):\n",
    "  # Iterate over each character and convert it to a one-hot encoded vector\n",
    "  for c_idx, char in enumerate(name):\n",
    "    target_data[n_idx, c_idx, char_to_idx[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and compile RNN network\n",
    "So far, you completed all the data preprocessing steps and have the input and target vectors ready. It is time to build the recurrent neural network. You'll create a small network architecture that will have 50 simple RNN nodes in the first layer followed by a dense layer. The dense layer will generate a probability distribution over the vocabulary for the next character. So, the size of the dense layer will be the same as the size of the vocabulary.\n",
    "\n",
    "The dataset is available as the DataFrame names. The length of the longest name is saved in variable max_len. The vocabulary is available in variable vocabulary. The SimpleRNN, Dense, Activation, TimeDistributed layers are already imported from keras.layers and the Sequential model is already imported from keras.models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5629e61868ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a Sequential model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Add SimpleRNN layer of 50 units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add SimpleRNN layer of 50 units\n",
    "model.add(SimpleRNN(50, input_shape=(max_len+1, len(vocabulary)), return_sequences=True))\n",
    "\n",
    "# Add a TimeDistributed Dense layer of size same as the vocabulary\n",
    "model.add(TimeDistributed(Dense(len(vocabulary), activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
