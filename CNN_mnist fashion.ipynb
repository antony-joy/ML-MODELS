{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_trainX shape: (60000, 28, 28, 1)\n",
      "cnn_testX shape: (10000, 28, 28, 1)\n",
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.5318 - accuracy: 0.8076\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2639 - accuracy: 0.9040\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2117 - accuracy: 0.9217\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.1690 - accuracy: 0.9380\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1319 - accuracy: 0.9512\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1076 - accuracy: 0.9593\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0889 - accuracy: 0.9673\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0716 - accuracy: 0.9745\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0595 - accuracy: 0.9779\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0538 - accuracy: 0.9802\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0409 - accuracy: 0.9855\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0387 - accuracy: 0.9866\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0316 - accuracy: 0.9884\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0271 - accuracy: 0.9902\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5021 - accuracy: 0.9110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.502129316329956, 0.9110000133514404]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "fash=fashion_mnist.load_data()\n",
    "(trainX, trainy), (testX, testy) = fash\n",
    "\n",
    "trainX=trainX/255.0   ## scaling \n",
    "testX=testX/255.0\n",
    "cnn_trainX = trainX.reshape(trainX.shape[0],28,28,1)#x_train.shape[0] = 60\n",
    "cnn_testX = testX .reshape(testX .shape[0],28,28,1)\n",
    "print('cnn_trainX shape: {}'.format(cnn_trainX.shape))\n",
    "print('cnn_testX shape: {}'.format(cnn_testX.shape))\n",
    "model3 = Sequential() # type of DNN\n",
    "model3.add(Conv2D(28, kernel_size=(3,3), input_shape = (28,28,1)))   #  layer 1\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Flatten()) \n",
    "\n",
    "model3.add(Dense(200, activation=\"relu\"))                #  layer 2\n",
    "\n",
    "model3.add(Dense(10, activation=tf.nn.softmax))         # layer 3\n",
    "\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.fit(cnn_trainX, trainy, epochs=15)\n",
    "\n",
    "model3.evaluate(cnn_testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/antony-joy/Data_sets/blob/main/tes.jpg?raw=true', \n",
    "\"testing.jpg\")\n",
    "img = Image.open(\"testing.jpg\")\n",
    "\n",
    "# converting it into numpy form  \n",
    "numpyimgdata = np.asarray(img) \n",
    "\n",
    "# shape \n",
    "print(numpyimgdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resizing: (28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "numpyimgdata=numpyimgdata/255\n",
    "\n",
    "\n",
    "load_img_rz = np.array(Image.open(\"testing.jpg\").resize((28,28)))\n",
    "Image.fromarray(load_img_rz).save('r_kolala.jpeg')\n",
    "print(\"After resizing:\",load_img_rz.shape)\n",
    "\n",
    "numpyimgdata_reshaped_grey = cv2.cvtColor(load_img_rz, cv2.COLOR_BGR2GRAY)\n",
    "your_new_array = np.expand_dims(numpyimgdata_reshaped_grey, axis=-1)\n",
    "your_new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "numpyimgdata_reshaped = your_new_array.reshape(-1,28, 28, 1)     # this is done make the image in\n",
    "                                                  # the same dimension of that of test and train data\n",
    "print(numpyimgdata_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [5]\n"
     ]
    }
   ],
   "source": [
    "image_predicted_array = model3.predict(numpyimgdata_reshaped)\n",
    "test_pred = np.argmax(image_predicted_array, axis=1)     \n",
    "print(\"predicted:\",test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This is actually wrong. It should be printed as a trouser which is denoted by 1 cause in mnist dataset 5 is sandal Label Description\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot\n",
    "\n",
    "I tried with different images, I am getting number 5(sandals) when I try with some boot or canvas shoes even. What seems to be the actual mistake here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
